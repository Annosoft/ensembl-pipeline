=head1 LICENSE

  Copyright (c) 1999-2011 The European Bioinformatics Institute and
  Genome Research Limited.  All rights reserved.

  This software is distributed under a modified Apache license.
  For license details, please see

    http://www.ensembl.org/info/about/code_licence.html

=head1 CONTACT

  Please email comments or questions to the public Ensembl
  developers list at <dev@ensembl.org>.

  Questions may also be sent to the Ensembl help desk at
  <helpdesk@ensembl.org>.

=cut

=head1 NAME

    Bio::EnsEMBL::Pipeline::Config::BatchQueue

=head1 SYNOPSIS

    use Bio::EnsEMBL::Pipeline::Config::BatchQueue;
    use Bio::EnsEMBL::Pipeline::Config::BatchQueue qw();

=head1 DESCRIPTION

    Configuration for pipeline batch queues. Specifies per-analysis
    resources and configuration, e.g. so that certain jobs are run
    only on certain nodes.

    It imports and sets a number of standard global variables into
    the calling package. Without arguments all the standard variables
    are set, and with a list, only those variables whose names are
    provided are set. The module will die if a variable which doesn't
    appear in its C<%Config> hash is asked to be set.

    The variables can also be references to arrays or hashes.

    Edit C<%Config> to add or alter variables.

    All the variables are in capitals, so that they resemble
    environment variables.

    To run a job only on a certain host, you have to add specific
    resource-requirements. This can be useful if you have special
    memory-requirements, for example if you like to run the job only
    on linux 64bit machines or if you want to run the job only on a
    specific host group. The commands bmgroup and lsinfo show you
    information about certain host-types / host-groups.

    Here are some example resource-statements / sub_args statements:

        sub_args => '-m bc_hosts',              # only use hosts of host-group 'bc_hosts' (see bmgroup)
        sub_args => '-m bc1_1',                 # only use hosts of host-group 'bc1_1'

        resource => 'select[type==X86_64]',     # use Linux 64 bit machines only
        resource => 'select[model==IBMBC2800]', # only run on IBMBC2800 hosts

        resource => 'alpha',                    # only run on DEC alpha
        resource => 'linux',                    # run on any machine capable of running 32-bit X86 Linux apps

=head2 Database throttling

  In order to run no more than 10 jobs concurrently against a database,
  we would submit jobs asking for 1000 tokens each (10,000/10=1000).
  
  bsub -R "rusage[myens_gen1tok=1000]" ....
  
  If you wanted to run no more than 500 jobs against the database, you
  would tell LSF that each job requires 20 tokens. (10,000/500=20).
  
  bsub -R "rusage[myens_gen1tok=20]" ....
  
  You will have to experiment to find out how many concurrent jobs your
  database can support; it will depend on how complex your sql queries are.
  
  By default jobs taken token for the whole lifetime of a job. However, some
  jobs only use a database at the start of a job. It is possible to add a
  duration to the token reservation so that the tokens are returned x minutes
  after the job has started.
  
  Durations are specified in hours or minutes.
  
  bsub -R "rusage[token=1000:duration=5]" ...   # reserve 1000 tokens for 5 minutes
  bsub -R "rusage[token=20:duration=12h]" ..  # reserve 20 tokens for 12 hours
  
  You can also specify the "decay" flag, which causes tokens to linearly
  decrease over the time period.
  
  bsub -R "rusage[token=10:duration=1h:decay=1]" #release 1 token per hour over the first 10 hours.
  
  [edit] Playing nicely with others
  
  If multiple users request tokens from the same database, LSF will arbirate
  between them using the normal faireshare facilities. However, you may wish
  to reserve tokens for other users to use. You can use a select statement to
  stop your jobs from using all of the available tokens, keeping them free for
  another user.
  
  eg: To reserve 2000 tokens for another user:
  
  bsub -R "rusage[token=100] select[token>2000]"
  
  The above example would allow 80 jobs to run at any one time. (10,000-2000)/100=80. 

=head1 METHODS

=cut


package Bio::EnsEMBL::Pipeline::Config::BatchQueue;

use strict;
use vars qw(%Config);

%Config = (

  # Depending on the job-submission-system you're using,
  # use LSF, you can also use 'Local'.
  #
  # For mor info look into:
  # /ensembl-pipeline/modules/Bio/EnsEMBL/Pipeline/BatchSubmission
  QUEUE_MANAGER => 'LSF', # use "SGE_GridEngine_v6" for running in ensembl cloud evironment

  DEFAULT_BATCH_SIZE  => 10,
  DEFAULT_RETRIES     => 3,
  DEFAULT_BATCH_QUEUE => '',    # Put in the queue of your choice, eg. 'normal'
  DEFAULT_RESOURCE    => '',
  DEFAULT_SUB_ARGS    => '',
  DEFAULT_OUTPUT_DIR  => '',
  DEFAULT_CLEANUP     => 'no',
  DEFAULT_VERBOSITY   => 'WARNING',

  # The two variables below are to overcome a bug in LSF. 
  # We're currently running the pre-exec with a different perl. lsf currently unsets the LD_LIBRARY_PATH 
  # which we need for certain 64bit libraries in pre-exec commands. (more info see LSF_LD_SECURITY variable ) 
    
  DEFAULT_LSF_PRE_EXEC_PERL =>'/usr/local/ensembl32/bin/perl', # ONLY use 32bit perl for lsf -pre-exec jobs
  DEFAULT_LSF_PERL =>'/usr/local/ensembl32/bin/perl', # ONLY use ensembl64/bin/perl for memory jobs > 4 gb
                                                     # SANGER farm : don't forget to source source /software/intel_cce_80/bin/iccvars.csh for big mem jobs 
                                                     #
  # At this number of jobs RuleManager will sleep for a certain period
  # of time if you effectively want this never to run set the value to
  # very high ie 100000 for a certain period of time this is important
  # for queue managers which cannot cope with large numbers of pending
  # jobs (e.g. early LSF versions and SGE)
  JOB_LIMIT           => 10000,

  JOB_STATUSES_TO_COUNT => ['PEND'],    # These are the jobs which will be 
                                        # counted. valid statuses for
                                        # this array are RUN, PEND, SSUSP, EXIT, DONE ; use 'qw' for Sun Grid Engine
  MARK_AWOL_JOBS => 1,
  MAX_JOB_SLEEP  => 3600,   # The maximun time to sleep for when job limit
                            # reached
  MIN_JOB_SLEEP => 120, # The minimum time to sleep for when job limit reached
  SLEEP_PER_JOB => 30,  # The amount of time to sleep per job when job limit
                        # reached

  DEFAULT_RUNNABLEDB_PATH => 'Bio/EnsEMBL/Analysis/RunnableDB',

  DEFAULT_RUNNER         => '',
  DEFAULT_RETRY_QUEUE    => 'long',
  DEFAULT_RETRY_SUB_ARGS => '',
  DEFAULT_RETRY_RESOURCE => '',

  QUEUE_CONFIG => [
    {
      logic_name      => 'repeatmask',
      batch_size      => 10,
      resource        => '',
      retries         => 3,
      sub_args        => '',
      runner          => '',
      queue           => 'normal',
      output_dir      => '/some_dir/',
      verbosity       => 'INFO',
      runnabledb_path => 'Bio/EnsEMBL/Analysis/RunnableDB',
      retry_queue     => '',
      retry_resource  => '',
      retry_sub_args  => '',
      lsf_perl        => '/usr/local/ensembl32/bin/perl',
    },
    {
      logic_name     => 'genscan',
      batch_size     => 10,
      resource       => '',
      retries        => 3,
      sub_args       => '',
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
        logic_name     => 'firstef',
        batch_size     => 10,
        resource       => '',
        retries        => 3,
        sub_args       => '',
        runner         => '',
        retry_queue    => '',
        retry_resource => '',
        retry_sub_args => '',
    },
    {
        logic_name     => 'cpg',
        batch_size     => 10,
        resource       => '',
        retries        => 3,
        sub_args       => '',
        runner         => '',
        retry_queue    => '',
        retry_resource => '',
        retry_sub_args => '',
    },
    {
        logic_name     => 'job_using_more_than_4_gig_of_memory',
        batch_size     => 10,
        resource       => '',
        retries        => 3,
        sub_args       => '',
        runner         => '',
        retry_queue    => '',
        retry_resource => '',
        retry_sub_args => '',
        lsf_perl        => '/usr/local/ensembl64/bin/perl',
    },
    {
      logic_name => 'eponine',
      batch_size => 2000,
      resource       => '',
      retries        => 3,
      sub_args       => '',
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
      logic_name => 'trf',
      batch_size => 2000,
      resource       => '',
      retries        => 3,
      sub_args       => '',
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
      logic_name => 'trnascan',
      batch_size => 2000,
      resource       => '',
      retries        => 3,
      sub_args       => '',
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
      logic_name => 'vertrna',
      batch_size => 600,
      resource       => '',
      retries        => 3,
      sub_args       => '-sp 100', #want all vertrnas to run together
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
      logic_name => 'unigene',
      batch_size => 600,
      resource       => '',
      retries        => 3,
      sub_args       => '-sp 95', #only want unigenes to run after vertrna
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },
    {
      logic_name => 'uniprot',
      batch_size => 500,
      resource       => '',
      retries        => 3,
      sub_args       => '-sp 90',
      runner         => '',
      retry_queue    => '',
      retry_resource => '',
      retry_sub_args => '',
    },

  ]
);

sub import {
  my ($callpack) = caller(0);    # Name of the calling package
  my $pack = shift;              # Need to move package off @_

  # Get list of variables supplied, or else all
  my @vars = @_ ? @_ : keys(%Config);
  return unless @vars;

  # Predeclare global variables in calling package
  eval "package $callpack; use vars qw("
    . join( ' ', map { '$' . $_ } @vars ) . ")";
  die $@ if $@;

  foreach (@vars) {
    if ( defined $Config{$_} ) {
      no strict 'refs';
      # Exporter does a similar job to the following
      # statement, but for function names, not
      # scalar variables:
      *{"${callpack}::$_"} = \$Config{$_};
    } else {
      die "Error: Config: $_ not known\n";
    }
  }
} ## end sub import

1;
